#!/usr/bin/env python3
"""
002027 è‚¡ç¥¨ä»£ç ä¸“é¡¹æµ‹è¯•
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

def test_002027_specifically():
    """ä¸“é—¨æµ‹è¯•002027è‚¡ç¥¨ä»£ç """
    print("ğŸ” 002027 ä¸“é¡¹æµ‹è¯•")
    print("=" * 60)
    
    test_ticker = "002027"
    
    try:
        from tradingagents.utils.logging_init import get_logger
        logger = get_logger("default")
        logger.setLevel("INFO")
        
        # æµ‹è¯•1: æ•°æ®è·å–
        print("\nğŸ“Š æµ‹è¯•1: æ•°æ®è·å–")
        from tradingagents.dataflows.interface import get_china_stock_data_tushare
        data = get_china_stock_data_tushare(test_ticker, "2025-07-01", "2025-07-15")
        
        if "002021" in data:
            print("âŒ æ•°æ®è·å–é˜¶æ®µå‘ç°é”™è¯¯ä»£ç  002021")
            return False
        else:
            print("âœ… æ•°æ®è·å–é˜¶æ®µæ­£ç¡®")
        
        # æµ‹è¯•2: åŸºæœ¬é¢åˆ†æ
        print("\nğŸ’° æµ‹è¯•2: åŸºæœ¬é¢åˆ†æ")
        from tradingagents.dataflows.optimized_china_data import OptimizedChinaDataProvider
        analyzer = OptimizedChinaDataProvider()
        report = analyzer._generate_fundamentals_report(test_ticker, data)
        
        if "002021" in report:
            print("âŒ åŸºæœ¬é¢åˆ†æé˜¶æ®µå‘ç°é”™è¯¯ä»£ç  002021")
            return False
        else:
            print("âœ… åŸºæœ¬é¢åˆ†æé˜¶æ®µæ­£ç¡®")
        
        # æµ‹è¯•3: LLMå¤„ç†
        print("\nğŸ¤– æµ‹è¯•3: LLMå¤„ç†")
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if api_key:
            from tradingagents.llm_adapters import ChatDashScopeOpenAI
            from langchain_core.messages import HumanMessage
            
            llm = ChatDashScopeOpenAI(model="qwen-turbo", temperature=0.1, max_tokens=500)
            
            prompt = f"è¯·åˆ†æè‚¡ç¥¨{test_ticker}çš„åŸºæœ¬é¢ï¼Œè‚¡ç¥¨åç§°æ˜¯åˆ†ä¼—ä¼ åª’ã€‚è¦æ±‚ï¼š1.å¿…é¡»ä½¿ç”¨æ­£ç¡®çš„è‚¡ç¥¨ä»£ç {test_ticker} 2.ä¸è¦ä½¿ç”¨ä»»ä½•å…¶ä»–è‚¡ç¥¨ä»£ç "
            
            response = llm.invoke([HumanMessage(content=prompt)])
            
            if "002021" in response.content:
                print("âŒ LLMå¤„ç†é˜¶æ®µå‘ç°é”™è¯¯ä»£ç  002021")
                print(f"é”™è¯¯å†…å®¹: {response.content[:200]}...")
                return False
            else:
                print("âœ… LLMå¤„ç†é˜¶æ®µæ­£ç¡®")
        else:
            print("âš ï¸ è·³è¿‡LLMæµ‹è¯•ï¼ˆæœªé…ç½®APIå¯†é’¥ï¼‰")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼002027è‚¡ç¥¨ä»£ç å¤„ç†æ­£ç¡®")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_002027_specifically()
